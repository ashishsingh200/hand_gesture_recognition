{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77d3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split,learning_curve\n",
    "from itertools import cycle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from log import get_logger\n",
    "from collections import Counter\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633a0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/ashishsingh/Desktop/SIGN/character and numbers/data/processed_data/data.pickle'\n",
    "MODEL_DIR = '/Users/ashishsingh/Desktop/SIGN/character and numbers/models'\n",
    "GRAPH_DIR = '/Users/ashishsingh/Desktop/SIGN/character and numbers/graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a8594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger setup\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.ERROR)\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84818aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(labels):\n",
    "    \"\"\"\n",
    "    Encode string/categorical labels into numeric values.\n",
    "    Returns the encoded labels and the fitted LabelEncoder.\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    labels_encoded = le.fit_transform(labels)\n",
    "    return labels_encoded, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acebe92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load processed data and ensure feature count consistency.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading data from {path}\")\n",
    "    data_dict = pickle.load(open(path, 'rb'))\n",
    "    data = np.asarray(data_dict['data'])\n",
    "    labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "    # Check feature length\n",
    "    for i, sample in enumerate(data):\n",
    "        if len(sample) != 84:\n",
    "            logger.error(f\"Sample {i} has {len(sample)} features, expected 84\")\n",
    "            raise ValueError(\"Feature length mismatch in data.\")\n",
    "\n",
    "    # Count label occurrences\n",
    "    label_counts = Counter(labels)\n",
    "\n",
    "    logger.info(f\"Data loaded successfully with {len(data)} total samples.\")\n",
    "    logger.info(f\"Number of unique labels: {len(label_counts)}\")\n",
    "    for label, count in label_counts.items():\n",
    "        logger.info(f\"Label '{label}': {count} samples\")\n",
    "\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3043a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train multiple models and return their accuracies and trained models.\n",
    "    \"\"\"\n",
    "    logger.info(\"Training models...\")\n",
    "\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(\n",
    "            n_estimators=200, max_depth=20,\n",
    "            min_samples_split=5, min_samples_leaf=2,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            n_estimators=100, max_depth=6,\n",
    "            learning_rate=0.1, random_state=42,\n",
    "            use_label_encoder=False, eval_metric='mlogloss'\n",
    "        ),\n",
    "        \"SVM\": SVC(kernel='rbf', C=1, probability=True, random_state=42),\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=500, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"NaiveBayes\": GaussianNB(),\n",
    "        \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        logger.info(f\"Training {name}...\")\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        results[name] = score\n",
    "        trained_models[name] = model\n",
    "        logger.info(f\"{name} Accuracy: {score*100:.2f}%\")\n",
    "\n",
    "    return results, trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f24df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_accuracies(results, save_dir=GRAPH_DIR):\n",
    "    \"\"\"\n",
    "    Save a bar plot of model accuracies.\n",
    "    \"\"\"\n",
    "    logger.info(\"Plotting model accuracies...\")\n",
    "    save_path = os.path.join(save_dir, 'model_accuracies.png')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(results.keys(), [v*100 for v in results.values()], color='lightgreen')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.ylim(0, 100)\n",
    "    for i, acc in enumerate(results.values()):\n",
    "        plt.text(i, acc*100 + 1, f\"{acc*100:.2f}%\", ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    logger.info(f\"Model accuracies saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa8356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, save_dir=GRAPH_DIR):\n",
    "    \"\"\"\n",
    "    Save confusion matrix for best model.\n",
    "    \"\"\"\n",
    "    logger.info(\"Plotting confusion matrix for best model...\")\n",
    "    save_path = os.path.join(save_dir, 'best_model_confusion_matrix.png')\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    logger.info(f\"Confusion matrix saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f8195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(X, y, save_dir=GRAPH_DIR):\n",
    "    \"\"\"\n",
    "    Save PCA visualization of data colored by labels with enhanced details.\n",
    "    \"\"\"\n",
    "    logger.info(\"Plotting PCA visualization...\")\n",
    "    pca = PCA(n_components=2)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    save_path = os.path.join(save_dir, 'pca_visualization.png')\n",
    "\n",
    "    plt.figure(figsize=(10, 8))  # Increased figure size for clarity\n",
    "    unique_labels = np.unique(y)\n",
    "    colors = plt.cm.get_cmap('viridis', len(unique_labels))  # Changed to 'viridis' for better distinction\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        plt.scatter(X_reduced[y == label, 0], X_reduced[y == label, 1], \n",
    "                    color=colors(i), label=f'Class {label}', alpha=0.6)  # Added alpha for overlap visibility\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.title(f'PCA Visualization of Data (Explained Variance: {pca.explained_variance_ratio_.sum()*100:.2f}%)')\n",
    "    plt.legend(title=\"Classes\", bbox_to_anchor=(1.05, 1), loc='upper left')  # Moved legend outside\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, format='png')  # Higher resolution\n",
    "    plt.close()\n",
    "\n",
    "    logger.info(f\"PCA visualization saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e307287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(labels, save_dir=GRAPH_DIR):\n",
    "    \"\"\"\n",
    "    Save a bar plot of class distribution.\n",
    "    \"\"\"\n",
    "    logger.info(\"Plotting class distribution...\")\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    save_path = os.path.join(save_dir, 'class_distribution.png')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(unique_labels, counts, color='skyblue')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Class Distribution in Dataset')\n",
    "    plt.xticks(unique_labels)\n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(unique_labels[i], count + 10, str(count), ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    logger.info(f\"Class distribution saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e9aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, best_model_name, save_dir=GRAPH_DIR):\n",
    "    \"\"\"\n",
    "    Save feature importance plot if the model supports it (e.g., XGBoost, RandomForest).\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        logger.info(f\"Plotting feature importance for {best_model_name}...\")\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1][:20]  # Top 20 features for clarity\n",
    "        save_path = os.path.join(save_dir, 'feature_importance.png')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(range(len(indices)), importances[indices], color='salmon')\n",
    "        plt.xticks(range(len(indices)), [f\"Feature {i}\" for i in indices], rotation=90)\n",
    "        plt.xlabel('Features (Indexed)')\n",
    "        plt.ylabel('Importance Score')\n",
    "        plt.title(f'Feature Importances for {best_model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "        logger.info(f\"Feature importance saved to {save_path}\")\n",
    "    else:\n",
    "        logger.warning(f\"{best_model_name} does not support feature_importances_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d4d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(model, x_test, y_test, le, save_dir=GRAPH_DIR):\n",
    "    \"\"\"\n",
    "    Save multi-class ROC curve for the best model.\n",
    "    \"\"\"\n",
    "    logger.info(\"Plotting ROC curve for best model...\")\n",
    "    y_test_bin = label_binarize(y_test, classes=range(len(le.classes_)))\n",
    "    y_prob = model.predict_proba(x_test)\n",
    "    n_classes = len(le.classes_)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_prob.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    save_path = os.path.join(save_dir, 'roc_curve.png')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC curve of class {le.classes_[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label=f'micro-average ROC curve (AUC = {roc_auc[\"micro\"]:.2f})',\n",
    "             color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-Class ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    logger.info(f\"ROC curve saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2389bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model, x_train, y_train, save_dir=GRAPH_DIR):\n",
    "    \"\"\"\n",
    "    Save learning curve for the best model using cross-validation.\n",
    "    \"\"\"\n",
    "    logger.info(\"Plotting learning curve for best model...\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        model, x_train, y_train, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "    )\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    save_path = os.path.join(save_dir, 'learning_curve.png')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_sizes, train_mean, '--', color=\"blue\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_mean, color=\"green\", label=\"Cross-validation score\")\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"blue\", alpha=0.15)\n",
    "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"green\", alpha=0.15)\n",
    "    plt.xlabel('Number of Training Samples')\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.title('Learning Curve for Best Model')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    logger.info(f\"Learning curve saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e56c46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(best_model_name, model, le, save_dir=MODEL_DIR):\n",
    "    \"\"\"\n",
    "    Save the best model and label encoder.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Saving best model: {best_model_name}\")\n",
    "    model_path = os.path.join(save_dir, 'best_model.p')\n",
    "    labels_path = os.path.join(save_dir, 'labels.p')\n",
    "\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump({'model': model}, f)\n",
    "    with open(labels_path, 'wb') as f:\n",
    "        pickle.dump(le, f)\n",
    "\n",
    "    logger.info(f\"Best model saved to {model_path}\")\n",
    "    logger.info(f\"Label encoder saved to {labels_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57da3da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 12:31:51,348 | INFO     | __main__ | Loading data from /Users/ashishsingh/Desktop/SIGN/character and numbers/data/processed_data/data.pickle\n",
      "2025-09-27 12:31:51,559 | INFO     | __main__ | Data loaded successfully with 51824 total samples.\n",
      "2025-09-27 12:31:51,560 | INFO     | __main__ | Number of unique labels: 36\n",
      "2025-09-27 12:31:51,560 | INFO     | __main__ | Label 'R': 633 samples\n",
      "2025-09-27 12:31:51,560 | INFO     | __main__ | Label 'U': 742 samples\n",
      "2025-09-27 12:31:51,561 | INFO     | __main__ | Label '9': 3044 samples\n",
      "2025-09-27 12:31:51,561 | INFO     | __main__ | Label '0': 3078 samples\n",
      "2025-09-27 12:31:51,561 | INFO     | __main__ | Label '7': 3388 samples\n",
      "2025-09-27 12:31:51,562 | INFO     | __main__ | Label 'I': 927 samples\n",
      "2025-09-27 12:31:51,562 | INFO     | __main__ | Label 'N': 964 samples\n",
      "2025-09-27 12:31:51,562 | INFO     | __main__ | Label 'G': 719 samples\n",
      "2025-09-27 12:31:51,563 | INFO     | __main__ | Label '6': 3335 samples\n",
      "2025-09-27 12:31:51,563 | INFO     | __main__ | Label 'Z': 670 samples\n",
      "2025-09-27 12:31:51,563 | INFO     | __main__ | Label '1': 3045 samples\n",
      "2025-09-27 12:31:51,564 | INFO     | __main__ | Label '8': 3424 samples\n",
      "2025-09-27 12:31:51,564 | INFO     | __main__ | Label 'T': 631 samples\n",
      "2025-09-27 12:31:51,564 | INFO     | __main__ | Label 'S': 660 samples\n",
      "2025-09-27 12:31:51,565 | INFO     | __main__ | Label 'A': 861 samples\n",
      "2025-09-27 12:31:51,565 | INFO     | __main__ | Label 'F': 741 samples\n",
      "2025-09-27 12:31:51,565 | INFO     | __main__ | Label 'O': 730 samples\n",
      "2025-09-27 12:31:51,566 | INFO     | __main__ | Label 'H': 866 samples\n",
      "2025-09-27 12:31:51,566 | INFO     | __main__ | Label 'M': 880 samples\n",
      "2025-09-27 12:31:51,566 | INFO     | __main__ | Label 'J': 920 samples\n",
      "2025-09-27 12:31:51,566 | INFO     | __main__ | Label 'C': 691 samples\n",
      "2025-09-27 12:31:51,567 | INFO     | __main__ | Label 'D': 1026 samples\n",
      "2025-09-27 12:31:51,567 | INFO     | __main__ | Label 'V': 610 samples\n",
      "2025-09-27 12:31:51,567 | INFO     | __main__ | Label 'Q': 691 samples\n",
      "2025-09-27 12:31:51,568 | INFO     | __main__ | Label '4': 3309 samples\n",
      "2025-09-27 12:31:51,568 | INFO     | __main__ | Label 'X': 561 samples\n",
      "2025-09-27 12:31:51,568 | INFO     | __main__ | Label '3': 3192 samples\n",
      "2025-09-27 12:31:51,570 | INFO     | __main__ | Label 'E': 728 samples\n",
      "2025-09-27 12:31:51,595 | INFO     | __main__ | Label 'B': 907 samples\n",
      "2025-09-27 12:31:51,595 | INFO     | __main__ | Label 'K': 859 samples\n",
      "2025-09-27 12:31:51,596 | INFO     | __main__ | Label 'L': 486 samples\n",
      "2025-09-27 12:31:51,596 | INFO     | __main__ | Label '2': 3172 samples\n",
      "2025-09-27 12:31:51,596 | INFO     | __main__ | Label 'Y': 691 samples\n",
      "2025-09-27 12:31:51,597 | INFO     | __main__ | Label '5': 3553 samples\n",
      "2025-09-27 12:31:51,597 | INFO     | __main__ | Label 'P': 645 samples\n",
      "2025-09-27 12:31:51,597 | INFO     | __main__ | Label 'W': 445 samples\n",
      "2025-09-27 12:31:51,640 | INFO     | __main__ | Plotting class distribution...\n",
      "2025-09-27 12:31:51,807 | INFO     | __main__ | Class distribution saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/graph/class_distribution.png\n",
      "2025-09-27 12:31:51,807 | INFO     | __main__ | Training models...\n",
      "2025-09-27 12:31:51,807 | INFO     | __main__ | Training RandomForest...\n",
      "2025-09-27 12:32:25,413 | INFO     | __main__ | RandomForest Accuracy: 99.48%\n",
      "2025-09-27 12:32:25,413 | INFO     | __main__ | Training XGBoost...\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:32:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025-09-27 12:32:43,170 | INFO     | __main__ | XGBoost Accuracy: 99.62%\n",
      "2025-09-27 12:32:43,171 | INFO     | __main__ | Training SVM...\n",
      "2025-09-27 12:33:19,420 | INFO     | __main__ | SVM Accuracy: 97.67%\n",
      "2025-09-27 12:33:19,421 | INFO     | __main__ | Training LogisticRegression...\n",
      "2025-09-27 12:33:23,077 | INFO     | __main__ | LogisticRegression Accuracy: 89.87%\n",
      "2025-09-27 12:33:23,077 | INFO     | __main__ | Training KNN...\n",
      "2025-09-27 12:33:23,520 | INFO     | __main__ | KNN Accuracy: 99.45%\n",
      "2025-09-27 12:33:23,522 | INFO     | __main__ | Training DecisionTree...\n",
      "2025-09-27 12:33:26,013 | INFO     | __main__ | DecisionTree Accuracy: 99.04%\n",
      "2025-09-27 12:33:26,014 | INFO     | __main__ | Training NaiveBayes...\n",
      "2025-09-27 12:33:26,098 | INFO     | __main__ | NaiveBayes Accuracy: 57.20%\n",
      "2025-09-27 12:33:26,098 | INFO     | __main__ | Training MLP...\n",
      "2025-09-27 12:34:41,613 | INFO     | __main__ | MLP Accuracy: 99.35%\n",
      "2025-09-27 12:34:41,616 | INFO     | __main__ | Plotting model accuracies...\n",
      "2025-09-27 12:34:41,709 | INFO     | __main__ | Model accuracies saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/graph/model_accuracies.png\n",
      "2025-09-27 12:34:41,709 | INFO     | __main__ | Best model: XGBoost with accuracy 99.62%\n",
      "2025-09-27 12:34:41,827 | INFO     | __main__ | Plotting confusion matrix for best model...\n",
      "2025-09-27 12:34:42,416 | INFO     | __main__ | Confusion matrix saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/graph/best_model_confusion_matrix.png\n",
      "2025-09-27 12:34:42,419 | INFO     | __main__ | Plotting feature importance for XGBoost...\n",
      "2025-09-27 12:34:42,486 | INFO     | __main__ | Feature importance saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/graph/feature_importance.png\n",
      "2025-09-27 12:34:42,486 | INFO     | __main__ | Plotting ROC curve for best model...\n",
      "2025-09-27 12:34:42,823 | INFO     | __main__ | ROC curve saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/graph/roc_curve.png\n",
      "2025-09-27 12:34:42,823 | INFO     | __main__ | Plotting learning curve for best model...\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:34:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:35:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:35:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:35:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:35:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:35:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:36:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:36:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:36:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:36:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:36:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:36:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:36:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:37:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:37:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:37:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:37:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:37:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:38:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:38:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:38:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:38:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:38:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:38:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:39:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:39:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:39:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:39:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:39:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:39:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:39:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:40:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:40:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:40:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:40:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:40:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:40:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:40:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:41:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:41:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:41:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ashishsingh/Desktop/Sign/venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [12:41:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025-09-27 12:43:01,171 | INFO     | __main__ | Learning curve saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/graph/learning_curve.png\n",
      "2025-09-27 12:43:01,173 | INFO     | __main__ | Plotting PCA visualization...\n",
      "/var/folders/c1/6c8s3wn93nd1yg_s50mdh4nc0000gn/T/ipykernel_21687/1070812044.py:12: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap('viridis', len(unique_labels))  # Changed to 'viridis' for better distinction\n",
      "2025-09-27 12:43:02,155 | INFO     | __main__ | PCA visualization saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/graph/pca_visualization.png\n",
      "2025-09-27 12:43:02,156 | INFO     | __main__ | Saving best model: XGBoost\n",
      "2025-09-27 12:43:02,185 | INFO     | __main__ | Best model saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/models/best_model.p\n",
      "2025-09-27 12:43:02,187 | INFO     | __main__ | Label encoder saved to /Users/ashishsingh/Desktop/SIGN/character and numbers/models/labels.p\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    data, labels = load_data(DATA_PATH)\n",
    "    labels_encoded, le = preprocess_labels(labels)\n",
    "\n",
    "    # Train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data,\n",
    "        labels_encoded,\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        stratify=labels,\n",
    "        random_state=42\n",
    "    )\n",
    "    plot_class_distribution(labels)\n",
    "\n",
    "    # Train models\n",
    "    results, trained_models = train_and_evaluate_models(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    # Plot accuracies\n",
    "    plot_model_accuracies(results)\n",
    "\n",
    "    # Find best model\n",
    "    best_model_name = max(results, key=results.get)\n",
    "    best_model = trained_models[best_model_name]\n",
    "    logger.info(f\"Best model: {best_model_name} with accuracy {results[best_model_name]*100:.2f}%\")\n",
    "\n",
    "    # Confusion matrix for best model\n",
    "    y_pred_best = best_model.predict(x_test)\n",
    "    plot_confusion_matrix(y_test, y_pred_best, le.classes_)\n",
    "\n",
    "    plot_feature_importance(best_model, best_model_name)\n",
    "    plot_roc_curve(best_model, x_test, y_test, le)\n",
    "    plot_learning_curve(best_model, x_train, y_train)\n",
    "\n",
    "    # Advanced visualizations\n",
    "    plot_pca(data, labels_encoded)\n",
    "\n",
    "    # Save best model & label encoder\n",
    "    save_best_model(best_model_name, best_model, le)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
