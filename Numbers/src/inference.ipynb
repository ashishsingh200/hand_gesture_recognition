{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3214b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import time\n",
    "from log import get_logger  # Import your existing logger\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e34937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Suppress matplotlib warnings in logs\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ac493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paths ===\n",
    "GRAPH_SAVE_DIR = Path(\"/Users/ashishsingh/Desktop/Sign01/graph\")\n",
    "GRAPH_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_PATH='/Users/ashishsingh/Desktop/Sign01/models/best_model.p'\n",
    "LABELS_PATH='/Users/ashishsingh/Desktop/Sign01/models/labels.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594efef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_labels(model_path=MODEL_PATH, labels_path=LABELS_PATH):\n",
    "    \"\"\"Load trained model and label encoder.\"\"\"\n",
    "    logger = get_logger(__name__)\n",
    "    try:\n",
    "        model = pickle.load(open(model_path, 'rb'))['model'] ##if the model saved as .keras then ##model = load_model(\"best_model.h5\")\n",
    "        label_encoder = pickle.load(open(labels_path, 'rb'))\n",
    "        logger.info(\"Model and labels loaded successfully.\")\n",
    "        return model, label_encoder\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model or labels: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab15ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_camera():\n",
    "    \"\"\"Initialize webcam.\"\"\"\n",
    "    logger = get_logger(__name__)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        logger.error(\"Unable to access webcam.\")\n",
    "        raise RuntimeError(\"Unable to access webcam.\")\n",
    "    logger.info(\"Webcam initialized successfully.\")\n",
    "    return cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a6c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_mediapipe():\n",
    "    \"\"\"Initialize MediaPipe Hands.\"\"\"\n",
    "    mp_hands = mp.solutions.hands\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    return hands, mp_hands, mp_drawing, mp_drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b55cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, hands, mp_hands, mp_drawing, mp_drawing_styles):\n",
    "    \"\"\"Extract landmarks and draw them on frame.\"\"\"\n",
    "    H, W, _ = frame.shape\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    data_aux = [0] * 84  # 2 hands × 21 landmarks × 2 coords\n",
    "    bbox_coords = None\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for i, hand_landmarks in enumerate(results.multi_hand_landmarks[:2]):\n",
    "            x_, y_, hand_data = [], [], []\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x_.append(landmark.x)\n",
    "                y_.append(landmark.y)\n",
    "\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                hand_data.append(landmark.x - min(x_))\n",
    "                hand_data.append(landmark.y - min(y_))\n",
    "\n",
    "            start_idx = i * 42\n",
    "            data_aux[start_idx:start_idx + 42] = hand_data\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style()\n",
    "            )\n",
    "\n",
    "            x1, y1 = int(min(x_) * W) - 10, int(min(y_) * H) - 10\n",
    "            x2, y2 = int(max(x_) * W) + 10, int(max(y_) * H) + 10\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "            bbox_coords = (x1, y1)\n",
    "\n",
    "    return frame, data_aux, bbox_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b66680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_display(data_aux, model, label_encoder, frame, bbox_coords):\n",
    "    \"\"\"Make prediction and draw it on the frame.\"\"\"\n",
    "    if bbox_coords is None or not data_aux:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Ensure 2D array shape: (1, n_features)\n",
    "        features = np.array(data_aux).reshape(1, -1)\n",
    "        \n",
    "        prediction = model.predict(features)\n",
    "        predicted_label = label_encoder.inverse_transform(prediction)[0]\n",
    "\n",
    "        x1, y1 = bbox_coords\n",
    "        cv2.putText(\n",
    "            frame, predicted_label, (x1, y1 - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3, cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "        return predicted_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Prediction Error] {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5885e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction_loop():\n",
    "    logger = get_logger(__name__)\n",
    "    model, label_encoder = load_model_and_labels()\n",
    "    cap = initialize_camera()\n",
    "    hands, mp_hands, mp_drawing, mp_drawing_styles = initialize_mediapipe()\n",
    "\n",
    "    predictions_counter = Counter()\n",
    "\n",
    "    plt.ion()  # Interactive mode for live graph\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                logger.error(\"Failed to read frame from webcam.\")\n",
    "                break\n",
    "\n",
    "            frame, data_aux, bbox_coords = process_frame(frame, hands, mp_hands, mp_drawing, mp_drawing_styles)\n",
    "            predicted_label = predict_and_display(data_aux, model, label_encoder, frame, bbox_coords)\n",
    "\n",
    "            cv2.imshow('Sign Language Classifier', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in prediction loop: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        plt.ioff()\n",
    "        logger.info(\"Prediction loop ended.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c07cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 10:44:25,721 | INFO     | __main__ | Model and labels loaded successfully.\n",
      "2025-09-27 10:44:27,177 | INFO     | __main__ | Webcam initialized successfully.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758950067.211650  155733 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1758950067.222043  156201 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1758950067.228414  156196 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1758950067.277363  156196 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "2025-09-27 10:46:39,629 | INFO     | __main__ | Prediction loop ended.\n"
     ]
    }
   ],
   "source": [
    "# --------------------- Script Entry --------------------- #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_prediction_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21384850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdb258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
